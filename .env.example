# If Using Llama Stack (To be implemented in the code)
REMOTE_BASE_URL= "http://llamastack-server:8321"

# Models
AVAILABLE_MODELS= "llama-4-scout-17b-16e-w4a16,granite-3-3-8b-instruct"

LLAMA_API_KEY= ""
LLAMA_MODEL= ""
LLAMA_URL= "<Model Url>/v1"

GRANITE_API_KEY= ""
GRANITE_MODEL= ""
GRANITE_URL= "Model Url/v1"

# optional environment variables for the demo (Not being used currently)
TEMPERATURE="0.0"
TOP_P="0.95"
MAX_TOKENS="512"
STREAM="False"

# for the RAG demos only - optional
VDB_PROVIDER="milvus"
VDB_EMBEDDING="all-MiniLM-L6-v2"
VDB_EMBEDDING_DIMENSION="384"
VECTOR_DB_CHUNK_SIZE="512"

# MCP-related
REMOTE_OCP_MCP_URL= "http://ocp-mcp-server:8000/sse"
